{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2fbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import glob\n",
    "import random\n",
    "import cmath\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7411a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dimen=1000\n",
    "Ngram=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c89cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210080 sentences have been loaded for train\n"
     ]
    }
   ],
   "source": [
    "#########Loading data##################\n",
    "\n",
    "LangLabels = ['bul', 'ces', 'dan', 'nld', 'deu', 'eng', 'est', 'fin', 'fra', 'ell', 'hun', 'ita',\n",
    "              'lav', 'lit', 'pol', 'por', 'ron', 'slk', 'slv', 'spa', 'swe']\n",
    "Traindata=[]\n",
    "Trainlabel=[]\n",
    "for i, Label in enumerate(LangLabels):\n",
    "    FilePath = os.path.join('language','training_texts',\"{}.txt\".format(Label))\n",
    "    with open(FilePath,'r', encoding='utf-8') as f:\n",
    "        inputseq=f.read()\n",
    "    senlist=inputseq.split('\\n')\n",
    "    for data in senlist:\n",
    "        Traindata.append(data)\n",
    "        Trainlabel.append(i)\n",
    "print(\"{} sentences have been loaded for train\".format(str(len(Traindata))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef942b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000 sentences have been loaded for test.\n"
     ]
    }
   ],
   "source": [
    "ShortLangLabels = ['bg', 'cs', 'da', 'nl', 'de', 'en', 'et', 'fi', 'fr', 'el', 'hu', 'it', 'lv', 'lt', 'pl', 'pt', 'ro', 'sk', 'sl', 'es', 'sv']\n",
    "Testdata=[]\n",
    "Testlabel=[]\n",
    "mp = dict()\n",
    "for i,key in enumerate(ShortLangLabels):\n",
    "    mp[key] = i\n",
    "TestFilePathList = glob.glob(os.path.join(\"language\", \"testing_texts\", \"*.txt\"))\n",
    "for i, TestFilePath in enumerate(TestFilePathList):\n",
    "    (_, TestFileName) = os.path.split(TestFilePath)\n",
    "    if not mp.__contains__(TestFileName[0:2]):\n",
    "        continue\n",
    "    Label = mp[TestFileName[0:2]]\n",
    "    with open(TestFilePath,'r',encoding='utf-8') as f:\n",
    "        InputSequence = f.read()\n",
    "    Testdata.append(InputSequence[:-1]) \n",
    "    Testlabel.append(Label)\n",
    "print(\"{} sentences have been loaded for test.\".format(str(len(Testdata))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b490fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdasi\\AppData\\Local\\Temp\\ipykernel_6060\\1174679383.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vector /= np.linalg.norm(vector)   #//////////////////////\n"
     ]
    }
   ],
   "source": [
    "#Polar\n",
    "K=21\n",
    "IM = dict() \n",
    "AM = dict()\n",
    "IAM = dict()\n",
    "LangLabels = []\n",
    "for key in range(K):\n",
    "    AM[key] = np.zeros(Dimen)\n",
    "    LangLabels.append(key)\n",
    "    \n",
    "def GenerateHV():\n",
    "    real_part = np.random.uniform(low=-1, high=1, size=Dimen)\n",
    "    complex_part = np.random.uniform(low=-1, high=1, size=Dimen)\n",
    "    RandomHV = real_part + 1j * complex_part\n",
    "    RandomHV = [cmath.phase(i) for i in RandomHV]\n",
    "    return RandomHV\n",
    "\n",
    "def CalculateNormalSimilarity(vector1, vector2):\n",
    "     return np.dot(vector1, vector2)\n",
    "\n",
    "def LookupIM(Key):\n",
    "    if not IM.__contains__(Key):\n",
    "        IM[Key] = GenerateHV();\n",
    "    return IM[Key]\n",
    "\n",
    "def NGramEncoding(InputSequence):\n",
    "    block = np.zeros([Ngram, Dimen])\n",
    "    sumHV = np.zeros(Dimen)\n",
    "    for i, Key in enumerate(InputSequence):\n",
    "        block = np.roll(block, (1, 1), (0, 1))\n",
    "        block[0] = LookupIM(Key)\n",
    "        if i >= Ngram - 1:\n",
    "            NGramHV = block[0]\n",
    "            for j in range(1, Ngram):\n",
    "                NGramHV = NGramHV * block[j]\n",
    "            sumHV += np.multiply(2,NGramHV)    #//////////////////////////\n",
    "    return sumHV\n",
    "\n",
    "def Normalization(vector):\n",
    "    vector /= np.linalg.norm(vector)   #//////////////////////\n",
    "    return vector\n",
    "\n",
    "length = len(Traindata)\n",
    "for i in range(length):\n",
    "    Data = Traindata[i]\n",
    "    Label = Trainlabel[i]\n",
    "    tmp = NGramEncoding(Data)\n",
    "    AM[Label] = AM[Label] + tmp\n",
    "for Label in LangLabels:\n",
    "    IAM[Label] = AM[Label]\n",
    "    AM[Label] = Normalization(AM[Label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "936e108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(Testdata)\n",
    "predict = []\n",
    "for i in range(length):\n",
    "    Data = Testdata[i]\n",
    "    TestHV = Normalization(NGramEncoding(Data))\n",
    "    maxAngle = -1\n",
    "    predicLang = -1\n",
    "    for j,LangLabel in enumerate(LangLabels):\n",
    "        angle = CalculateNormalSimilarity(AM[LangLabel], TestHV)\n",
    "        if angle > maxAngle:\n",
    "            maxAngle = angle\n",
    "            predicLang = LangLabel\n",
    "    predict.append(predicLang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63d0fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score,confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(\"Accuracy score: \",accuracy_score(Testlabel,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77596f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
